{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aleebaqi/SpeakingClock_AzureModuleProject/blob/main/speaking_clock.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MS Azure Module Assignment\n",
        "\n",
        "Azure AI Speech Service Integration, Voice Recognition, and Translation"
      ],
      "metadata": {
        "id": "zR72hn9DCWoz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install azure.cognitiveservices.speech\n",
        "!pip install azure-cognitiveservices-language-textanalytics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3p6WnXAXmiCY",
        "outputId": "2fa0b183-5866-4841-b541-cf67186772d2"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting azure.cognitiveservices.speech\n",
            "  Downloading azure_cognitiveservices_speech-1.32.1-py3-none-manylinux1_x86_64.whl (3.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: azure.cognitiveservices.speech\n",
            "Successfully installed azure.cognitiveservices.speech-1.32.1\n",
            "Collecting azure-cognitiveservices-language-textanalytics\n",
            "  Downloading azure_cognitiveservices_language_textanalytics-0.2.1-py2.py3-none-any.whl (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m945.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting msrest>=0.6.21 (from azure-cognitiveservices-language-textanalytics)\n",
            "  Downloading msrest-0.7.1-py3-none-any.whl (85 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.4/85.4 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting azure-common~=1.1 (from azure-cognitiveservices-language-textanalytics)\n",
            "  Downloading azure_common-1.1.28-py2.py3-none-any.whl (14 kB)\n",
            "Collecting azure-mgmt-core<2.0.0,>=1.2.0 (from azure-cognitiveservices-language-textanalytics)\n",
            "  Downloading azure_mgmt_core-1.4.0-py3-none-any.whl (27 kB)\n",
            "Collecting azure-core<2.0.0,>=1.26.2 (from azure-mgmt-core<2.0.0,>=1.2.0->azure-cognitiveservices-language-textanalytics)\n",
            "  Downloading azure_core-1.29.4-py3-none-any.whl (192 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m192.4/192.4 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from msrest>=0.6.21->azure-cognitiveservices-language-textanalytics) (2023.7.22)\n",
            "Collecting isodate>=0.6.0 (from msrest>=0.6.21->azure-cognitiveservices-language-textanalytics)\n",
            "  Downloading isodate-0.6.1-py2.py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.7/41.7 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests-oauthlib>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from msrest>=0.6.21->azure-cognitiveservices-language-textanalytics) (1.3.1)\n",
            "Requirement already satisfied: requests~=2.16 in /usr/local/lib/python3.10/dist-packages (from msrest>=0.6.21->azure-cognitiveservices-language-textanalytics) (2.31.0)\n",
            "Requirement already satisfied: six>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from azure-core<2.0.0,>=1.26.2->azure-mgmt-core<2.0.0,>=1.2.0->azure-cognitiveservices-language-textanalytics) (1.16.0)\n",
            "Collecting typing-extensions>=4.6.0 (from azure-core<2.0.0,>=1.26.2->azure-mgmt-core<2.0.0,>=1.2.0->azure-cognitiveservices-language-textanalytics)\n",
            "  Downloading typing_extensions-4.8.0-py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests~=2.16->msrest>=0.6.21->azure-cognitiveservices-language-textanalytics) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests~=2.16->msrest>=0.6.21->azure-cognitiveservices-language-textanalytics) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests~=2.16->msrest>=0.6.21->azure-cognitiveservices-language-textanalytics) (2.0.6)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.5.0->msrest>=0.6.21->azure-cognitiveservices-language-textanalytics) (3.2.2)\n",
            "Installing collected packages: azure-common, typing-extensions, isodate, azure-core, msrest, azure-mgmt-core, azure-cognitiveservices-language-textanalytics\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.5.0\n",
            "    Uninstalling typing_extensions-4.5.0:\n",
            "      Successfully uninstalled typing_extensions-4.5.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.13.0 requires typing-extensions<4.6.0,>=3.6.6, but you have typing-extensions 4.8.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed azure-cognitiveservices-language-textanalytics-0.2.1 azure-common-1.1.28 azure-core-1.29.4 azure-mgmt-core-1.4.0 isodate-0.6.1 msrest-0.7.1 typing-extensions-4.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Recording Your Voice in English:\n",
        "Using an audio recording tool, record your voice in English, including an introduction of yourself. The introduction should not exceed two minutes in duration.\n",
        "\n",
        "Save the recorded audio as a .wav file. Ensure that the file name is unique and meaningful, such as \"yourname_intro.wav.\"\n",
        "\n",
        "Place the recorded audio file in the same directory as the provided sample file \"time.wav.\""
      ],
      "metadata": {
        "id": "LsS_Of34JLQs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "audio_file = \"/content/my_intro_azureproject.wav\"\n",
        "\n",
        "if os.path.exists(audio_file):\n",
        "    print(\"File exists\")\n",
        "else:\n",
        "    print(\"File does not exist\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d3DiwVvvo0OV",
        "outputId": "bf4e3934-da0b-4e2e-a69f-9c5b3d2ccc81"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fixation of the audio file:"
      ],
      "metadata": {
        "id": "gQduCzojN2vu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ffmpeg -i my_intro_azureproject.wav -acodec pcm_s16le -ar 16000 my_intro_azureproject_fixed.wav\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mI75GwIE7qpm",
        "outputId": "2e14a2a0-9301-416e-d1a5-f329e8d70bc3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ffmpeg version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2000-2021 the FFmpeg developers\n",
            "  built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
            "  libavutil      56. 70.100 / 56. 70.100\n",
            "  libavcodec     58.134.100 / 58.134.100\n",
            "  libavformat    58. 76.100 / 58. 76.100\n",
            "  libavdevice    58. 13.100 / 58. 13.100\n",
            "  libavfilter     7.110.100 /  7.110.100\n",
            "  libswscale      5.  9.100 /  5.  9.100\n",
            "  libswresample   3.  9.100 /  3.  9.100\n",
            "  libpostproc    55.  9.100 / 55.  9.100\n",
            "\u001b[0;35m[aac @ 0x5c4b89d4e0c0] \u001b[0m\u001b[0;33mEstimating duration from bitrate, this may be inaccurate\n",
            "\u001b[0mInput #0, aac, from 'my_intro_azureproject.wav':\n",
            "  Duration: 00:00:09.96, bitrate: 99 kb/s\n",
            "  Stream #0:0: Audio: aac (LC), 44100 Hz, mono, fltp, 99 kb/s\n",
            "Stream mapping:\n",
            "  Stream #0:0 -> #0:0 (aac (native) -> pcm_s16le (native))\n",
            "Press [q] to stop, [?] for help\n",
            "Output #0, wav, to 'my_intro_azureproject_fixed.wav':\n",
            "  Metadata:\n",
            "    ISFT            : Lavf58.76.100\n",
            "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 16000 Hz, mono, s16, 256 kb/s\n",
            "    Metadata:\n",
            "      encoder         : Lavc58.134.100 pcm_s16le\n",
            "size=       1kB time=00:00:00.00 bitrate=N/A speed=N/A    \rsize=     314kB time=00:00:10.05 bitrate= 256.1kbits/s speed= 219x    \n",
            "video:0kB audio:314kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.024243%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modifying \"speaking-clock.py\" Code:\n",
        "Open the \"speaking-clock.py\" file in a text editor or IDE.\n",
        "\n",
        "Utilize the Azure AI Speech service knowledge gained in recent labs to locate the code section responsible for transcribing the \"time.wav\" file.\n",
        "\n",
        "Modify this section to transcribe your recorded audio file (\"yourname_intro.wav\") instead.\n",
        "\n",
        "Ensure that the transcription results are stored separately for English."
      ],
      "metadata": {
        "id": "VfbNUB_JJDFB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import azure.cognitiveservices.speech as speechsdk\n",
        "\n",
        "# Set your Azure subscription key and service region\n",
        "subscription_key = \"900b06ec4b554b6e89ca637073b0624f\"\n",
        "region = \"eastus\"\n",
        "\n",
        "# Define the path to your audio file\n",
        "audio_file_path = \"/content/my_intro_azureproject_fixed.wav\"\n",
        "\n",
        "# Create a directory to store transcription results\n",
        "if not os.path.exists(\"transcription_results\"):\n",
        "    os.makedirs(\"transcription_results\")\n",
        "\n",
        "def transcribe_audio(audio_file, language):\n",
        "    # Set up the Azure Speech service client\n",
        "    speech_config = speechsdk.SpeechConfig(subscription=subscription_key, region=region)\n",
        "    audio_config = speechsdk.audio.AudioConfig(filename=audio_file)\n",
        "\n",
        "    # Initialize the speech recognizer\n",
        "    speech_recognizer = speechsdk.SpeechRecognizer(speech_config=speech_config, audio_config=audio_config)\n",
        "\n",
        "    # Perform speech recognition\n",
        "    result = speech_recognizer.recognize_once()\n",
        "\n",
        "    if result.reason == speechsdk.ResultReason.RecognizedSpeech:\n",
        "        # Transcription successful\n",
        "        print(f\"Recognized ({language}): {result.text}\")\n",
        "\n",
        "        # Store the transcription result separately for English\n",
        "        if language.lower() == \"en\":\n",
        "            output_file = os.path.join(\"transcription_results\", \"english_transcription.txt\")\n",
        "            with open(output_file, \"w\") as english_file:\n",
        "                english_file.write(result.text)\n",
        "    elif result.reason == speechsdk.ResultReason.NoMatch:\n",
        "        print(\"No speech could be recognized\")\n",
        "    elif result.reason == speechsdk.ResultReason.Canceled:\n",
        "        cancellation_details = result.cancellation_details.reason\n",
        "        print(f\"Speech Recognition canceled: {cancellation_details}\")\n",
        "\n",
        "# Transcribe the audio for English\n",
        "transcribe_audio(audio_file_path, language=\"en\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ou94u9fqCgDe",
        "outputId": "109ac5e1-fb01-4b8b-e45a-e7314e993caa"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech Recognition canceled: CancellationReason.Error\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating a Function to Call Your Name:\n",
        "Use the Azure AI Speech service knowledge to create a new Python function in the \"speaking-clock.py\" file.\n",
        "\n",
        "Name this function after your name, for example, \"YourNameCall.\"\n",
        "\n",
        "Inside the function, use the Azure AI Speech service to recognize and read your name from the recorded audio."
      ],
      "metadata": {
        "id": "tCuvO0lZIxxH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import azure.cognitiveservices.speech as speechsdk\n",
        "\n",
        "def YourNameCall(audio_file, name):\n",
        "    # Set your Azure subscription key and service region\n",
        "    subscription_key = \"900b06ec4b554b6e89ca637073b0624f\"\n",
        "    region = \"eastus\"\n",
        "\n",
        "    # Set up the Azure Speech service client\n",
        "    speech_config = speechsdk.SpeechConfig(subscription=subscription_key, region=region)\n",
        "    audio_config = speechsdk.audio.AudioConfig(filename=audio_file)\n",
        "\n",
        "    # Initialize the speech recognizer\n",
        "    speech_recognizer = speechsdk.SpeechRecognizer(speech_config=speech_config, audio_config=audio_config)\n",
        "\n",
        "    # Perform speech recognition\n",
        "    result = speech_recognizer.recognize_once()\n",
        "\n",
        "    if result.reason == speechsdk.ResultReason.RecognizedSpeech:\n",
        "        # Check if your name is recognized in the transcription\n",
        "        if name.lower() in result.text.lower():\n",
        "            # Your name was recognized\n",
        "            print(f\"Hello, {name}!\")\n",
        "        else:\n",
        "            # Your name was not recognized\n",
        "            print(\"Sorry, I didn't hear your name.\")\n",
        "    elif result.reason == speechsdk.ResultReason.NoMatch:\n",
        "        print(\"No speech could be recognized\")\n",
        "    elif result.reason == speechsdk.ResultReason.Canceled:\n",
        "        cancellation_details = result.cancellation_details.reason\n",
        "        print(f\"Speech Recognition canceled: {cancellation_details}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    audio_file = \"/content/my_intro_azureproject_fixed.wav\"  # Replace with the path to your audio file\n",
        "    your_name = \"AliMuhammad\"  # Replace with your name\n",
        "    YourNameCall(audio_file, your_name)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qmvKeg1t6jQ3",
        "outputId": "7f8dfa10-7da2-4afb-833f-2c06674ff938"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech Recognition canceled: CancellationReason.Error\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Translation Using Azure Translator Service:\n",
        "Leverage the Translator service knowledge from previous labs (Translator Service) to translate the English transcription into Urdu.\n",
        "\n",
        "Implement this translation within the \"speaking-clock.py\" file.\n",
        "\n",
        "Store the translated audio separately."
      ],
      "metadata": {
        "id": "Qbk80KTyMjSe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import azure.cognitiveservices.speech as speechsdk\n",
        "from azure.cognitiveservices.language.textanalytics import TextAnalyticsClient\n",
        "from msrest.authentication import CognitiveServicesCredentials\n",
        "\n",
        "def translate_to_urdu(text, subscription_key, region):\n",
        "    # Set up the Azure Translator service client\n",
        "    credentials = CognitiveServicesCredentials(subscription_key)\n",
        "    text_analytics_client = TextAnalyticsClient(endpoint=f\"https://{region}.api.cognitive.microsofttranslator.com\", credentials=credentials)\n",
        "\n",
        "    # Translate text from English to Urdu\n",
        "    translation_response = text_analytics_client.translators(text, source_language=\"en\", target_language=\"ur\")\n",
        "    urdu_translation = translation_response[0].translations[0].text\n",
        "\n",
        "    return urdu_translation\n",
        "\n",
        "def transcribe_and_translate(audio_file, name, translator_subscription_key, translator_region):\n",
        "    # Set your Azure Speech service subscription key and region\n",
        "    subscription_key = \"900b06ec4b554b6e89ca637073b0624f\"\n",
        "    region = \"eastus\"\n",
        "\n",
        "    # Set up the Azure Speech service client\n",
        "    speech_config = speechsdk.SpeechConfig(subscription=subscription_key, region=region)\n",
        "    audio_config = speechsdk.audio.AudioConfig(filename=audio_file)\n",
        "\n",
        "    # Initialize the speech recognizer\n",
        "    speech_recognizer = speechsdk.SpeechRecognizer(speech_config=speech_config, audio_config=audio_config)\n",
        "\n",
        "    # Perform speech recognition\n",
        "    result = speech_recognizer.recognize_once()\n",
        "\n",
        "    if result.reason == speechsdk.ResultReason.RecognizedSpeech:\n",
        "        # Check if your name is recognized in the transcription\n",
        "        if name.lower() in result.text.lower():\n",
        "            # Greet in English\n",
        "            print(f\"Hello, {name}!\")\n",
        "\n",
        "            # Translate the transcription to Urdu\n",
        "            urdu_translation = translate_to_urdu(result.text, translator_subscription_key, translator_region)\n",
        "\n",
        "            # Print the Urdu translation\n",
        "            print(f\"Urdu Translation: {urdu_translation}\")\n",
        "        else:\n",
        "            # Your name was not recognized\n",
        "            print(\"Sorry, I didn't hear your name.\")\n",
        "    elif result.reason == speechsdk.ResultReason.NoMatch:\n",
        "        print(\"No speech could be recognized\")\n",
        "    elif result.reason == speechsdk.ResultReason.Canceled:\n",
        "        cancellation_details = result.cancellation_details.reason\n",
        "        print(f\"Speech Recognition canceled: {cancellation_details}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    audio_file_path = \"/content/my_intro_azureproject_fixed.wav\"  # Replace with the path to your audio file\n",
        "    your_name = \"AliMuhammad\"  # Replace with your name\n",
        "    translator_subscription_key = \"900b06ec4b554b6e89ca637073b0624f\"  # Replace with your Translator service key\n",
        "    translator_region = \"eastus\"  # Replace with your Translator service region\n",
        "\n",
        "    transcribe_and_translate(audio_file_path, your_name, translator_subscription_key, translator_region)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yh6fBTtUJsIn",
        "outputId": "ba07d892-f543-4918-919c-98bb93b7a3ba"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech Recognition canceled: CancellationReason.Error\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Zip all submissions into one zip file, named \"YourName_LMSID.zip\"."
      ],
      "metadata": {
        "id": "3m_dyPOXDyjV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cd E:\\DSAI-NUST Course\\Azure Project\n",
        "!zip AliMuhammad_LMSID.zip speaking-clock.py my_intro_azureproject_fixed.wav translation.wav GitHub_Link.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-M8xOEQgQHmu",
        "outputId": "6881c488-b3f0-44a2-92b3-a64c66e349c8"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: cd: too many arguments\n",
            "\tzip warning: name not matched: speaking-clock.py\n",
            "\tzip warning: name not matched: translation.wav\n",
            "\tzip warning: name not matched: GitHub_Link.txt\n",
            "  adding: my_intro_azureproject_fixed.wav (deflated 13%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Github Link: https://github.com/aleebaqi"
      ],
      "metadata": {
        "id": "cPV5jBGBNqLE"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNkkSNZ2X7gS+G6T2PRPTcX",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}